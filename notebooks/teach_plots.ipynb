{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473143fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf443ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db0f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib_views as views\n",
    "except ModuleNotFoundError:\n",
    "    cwd = pathlib.Path().resolve().parent\n",
    "    sys.path.append(str(cwd))\n",
    "    import matplotlib_views as views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc4a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bed336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31323a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib import patheffects\n",
    "from matplotlib import ticker\n",
    "from matplotlib import rcParams\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7220269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_views import histograms\n",
    "from matplotlib_views import formats\n",
    "from matplotlib_views import styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321c8ce",
   "metadata": {},
   "source": [
    "## Create some fake data\n",
    "\n",
    "Teaching style is good when fake data is used. E.g. not to be read out explicit \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set presentation dimensions\n",
    "# views.set_global_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d633d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788d7fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793ae06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b49a204d",
   "metadata": {},
   "source": [
    "## Empty example figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598424b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with plt.xkcd():\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
    "\n",
    "fig, ax = views.get_plot()\n",
    "\n",
    "ax.spines[\"right\"].set_color(\"none\")\n",
    "ax.spines[\"top\"].set_color(\"none\")\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_ylim([-30, 10])\n",
    "\n",
    "data = np.ones(100)\n",
    "data[70:] -= np.arange(30)\n",
    "\n",
    "ax.annotate(\n",
    "    'THE DAY I REALIZED\\nI COULD COOK BACON\\nWHENEVER I WANTED',\n",
    "    xy=(70, 1), arrowprops=dict(arrowstyle='->', lw=2), xytext=(15, -10), size=20,\n",
    "    path_effects=[patheffects.withStroke(linewidth=3, foreground=\"w\")]\n",
    ")\n",
    "\n",
    "ax.plot(data)\n",
    "\n",
    "ax.set_xlabel(r'time $\\rightarrow$')\n",
    "#ax.set_xlabel(r'$\\rho/\\rho_{ref}\\;\\rightarrow$', color='red')\n",
    "ax.set_ylabel(r'my overall health $\\rightarrow$')\n",
    "fig.text(\n",
    "    0.5,\n",
    "    0.05,\n",
    "    '\"Stove Ownership\" from xkcd by Randall Munroe',\n",
    "    ha='center'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1daa4a6",
   "metadata": {},
   "source": [
    "## Predicted vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335df70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@styles.use_teach\n",
    "def predicted_vs_actual():\n",
    "    \n",
    "    # Data\n",
    "    x_axis = np.arange(-10, 10)\n",
    "    n_points = len(x_axis)\n",
    "    \n",
    "    predictions_a = np.random.normal(loc=0.0, scale=1, size=n_points) + x_axis\n",
    "    predictions_b = np.random.normal(loc=0.0, scale=2, size=n_points)\n",
    "    predictions_c = (\n",
    "        np.random.normal(loc=0.0, scale=0.5, size=n_points)*np.linspace(1, 30, n_points) + x_axis\n",
    "    )\n",
    "    predictions = [predictions_a, predictions_b, predictions_c]\n",
    "    \n",
    "    size = 5\n",
    "    n_ax = len(predictions)\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        1,\n",
    "        n_ax,\n",
    "        sharey=False,\n",
    "        sharex=False,\n",
    "        figsize=(n_ax * size, size),\n",
    "    )\n",
    "\n",
    "    for ax, data in zip(axs, predictions):\n",
    "\n",
    "        x_ticks = styles.simple_ticks(x_axis)\n",
    "        y_ticks = styles.simple_ticks(list(data)+list(x_ticks))\n",
    "        \n",
    "        ax.set_xticks(x_ticks)\n",
    "        ax.set_yticks(y_ticks)\n",
    "        \n",
    "        ax.plot(x_axis, x_axis, \"k-\", **styles.outline)\n",
    "        ax.scatter(x_axis, data)\n",
    "    \n",
    "    \n",
    "    axs[0].set_ylabel(\"Predicted\")\n",
    "    axs[1].set_xlabel(\"Actual\")\n",
    "    \n",
    "    styles.name_axes(axs, loc=\"top right\")\n",
    "    styles.simple_axes(axs)\n",
    "    \n",
    "    views.save(\"fig/fig_predicted_vs_actual\", fig=fig)\n",
    "    \n",
    "    return\n",
    "    \n",
    "predicted_vs_actual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a86298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f62531ff",
   "metadata": {},
   "source": [
    "## Residual vs Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "@styles.use_teach\n",
    "def residual_vs_predicted(a):\n",
    "    \n",
    "    size = 5\n",
    "    n_ax = 3\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        1,\n",
    "        n_ax,\n",
    "        sharey=False,\n",
    "        sharex=False,\n",
    "        figsize=(n_ax * size, size),\n",
    "    )\n",
    "\n",
    "    x_axis = np.arange(-10, 10)\n",
    "    n_points = len(x_axis)\n",
    "\n",
    "    # A\n",
    "    mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    residuals_random = np.random.normal(mu, sigma, n_points)\n",
    "    x_ticks = styles.simple_ticks(x_axis)\n",
    "    \n",
    "    # Zero line\n",
    "    axs[0].plot(x_ticks, [0.0]*3, 'k-')\n",
    "    axs[0].text(\n",
    "        np.mean(x_ticks), 0.0, \"Zero\", horizontalalignment='center', verticalalignment='center',\n",
    "        **styles.outline,\n",
    "    )\n",
    "    \n",
    "    axs[0].scatter(x_axis, residuals_random)\n",
    "    axs[0].set_ylabel(\"Residual\")\n",
    "    axs[0].set_xticks(x_ticks)\n",
    "    axs[0].set_yticks(styles.simple_ticks(residuals_random))\n",
    "    #axs[0].text(0.9, 0.9, 'A)', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "    \n",
    "    # B\n",
    "    mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    residuals_nonlinear = x_axis**2 + np.random.normal(mu, sigma, n_points)\n",
    "    axs[1].scatter(x_axis, residuals_nonlinear)\n",
    "    axs[1].set_xlabel(\"Actual\")\n",
    "    axs[1].set_xticks(styles.simple_ticks(x_axis))\n",
    "    axs[1].set_yticks(styles.simple_ticks(residuals_nonlinear))\n",
    "\n",
    "    # C\n",
    "    mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    residuals_nonlinear = np.random.normal(mu, sigma, n_points)\n",
    "    residuals_nonlinear[-1] = -1\n",
    "    x_axis_limit = x_axis/4\n",
    "    x_axis_limit[-1] = x_axis[-1]\n",
    "    axs[2].scatter(x_axis_limit, residuals_nonlinear)\n",
    "    axs[2].set_xticks(styles.simple_ticks(x_axis_limit))\n",
    "    axs[2].set_yticks(styles.simple_ticks(residuals_nonlinear))\n",
    "\n",
    "    # Dumb axes\n",
    "    styles.name_axes(axs)\n",
    "    styles.simple_axes(axs)\n",
    "    \n",
    "    views.save(\"fig/fig_residual_vs_actual\", fig=fig)\n",
    "\n",
    "residual_vs_predicted(\"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8a2cdf",
   "metadata": {},
   "source": [
    "Plotted is the residual (regression error ($Residual = Observed - Predicted$)) vs predicted values. A) A good fit will show the values bounce randomly around zero. B) The model doesn't describe how property behave as x changes, could be non-linear data fitted to linear model. C) Indication of property cliffs/outliers, with uneven data distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b486bc4",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885425db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@styles.use_teach\n",
    "def data_distribution():\n",
    "    \n",
    "    size = 5\n",
    "    n_ax = 3\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        1,\n",
    "        n_ax,\n",
    "        sharey=False,\n",
    "        sharex=False,\n",
    "        figsize=(n_ax * size, size),\n",
    "    )\n",
    "    hist_kwargs = dict(bins=15, color=\"k\", rwidth=0.85,)  \n",
    "    \n",
    "    data_a = np.random.normal(size=500, scale=1)\n",
    "    data_b = (\n",
    "        np.random.normal(loc=0.0, size=2_000, scale=10)\n",
    "    )\n",
    "    data_b = data_b[np.where(data_b > 0.1)]\n",
    "    data_b = list(data_b) + list(np.random.normal(loc=0.0, size=100))\n",
    "    \n",
    "    data_c = (\n",
    "        list(np.random.normal(loc=10.0, size=250, scale=2)) +\n",
    "        list(np.random.normal(scale=2, loc=0.0,size=100))\n",
    "    )\n",
    "    \n",
    "    data_list = [data_a, data_b, data_c]\n",
    "    \n",
    "    for ax, data in zip(axs, data_list):\n",
    "        arr, bins, patches = ax.hist(data, **hist_kwargs)\n",
    "        ax.set_xticks(styles.simple_ticks(data))\n",
    "        ax.set_yticks(styles.simple_ticks(arr))\n",
    " \n",
    "    \n",
    "    axs[0].set_ylabel(\"Count\")\n",
    "    axs[1].set_xlabel(\"Property\")\n",
    "    \n",
    "    # Dumb axes\n",
    "    styles.name_axes(axs)\n",
    "    styles.simple_axes(axs)\n",
    "    \n",
    "    views.save(\"fig/fig_data_distribution\", fig=fig)\n",
    "    \n",
    "    \n",
    "data_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362805a4",
   "metadata": {},
   "source": [
    "## Varience Explanined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab517ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def residual(y_pred, y_true):\n",
    "    return y_pred - y_true\n",
    "\n",
    "def variance_explained(y_pred, y_true):\n",
    "    res = residual(y_pred, y_true)\n",
    "    ve = 1 - np.var(res) / np.var(y_true)\n",
    "    return ve\n",
    "\n",
    "n_points = 5\n",
    "\n",
    "truth = np.random.random(n_points)*10\n",
    "predictions = np.random.random(n_points)*5\n",
    "\n",
    "variance_explained(predictions, truth)\n",
    "\n",
    "@styles.use_teach\n",
    "def varience_explained_plot():\n",
    "    \n",
    "    _lineprops = dict(linestyle='-', linewidth=3, color='k')\n",
    "    _lineprops_mean = dict(linestyle='-', linewidth=2.5, color='k', zorder=0)\n",
    "    \n",
    "    kwargs = dict(\n",
    "        boxprops=_lineprops, capprops=_lineprops, whiskerprops=_lineprops,\n",
    "        medianprops=_lineprops_mean,\n",
    "        widths=0.4,\n",
    "    )\n",
    "    \n",
    "    # Data\n",
    "    x_axis = np.arange(-10, 10)\n",
    "    n_points = len(x_axis)\n",
    "    \n",
    "    data_a = [0.95, 0.9, 0.85, 0.99]\n",
    "    data_b = [0.9, 0.3, 0.7, 0.8]\n",
    "    data_c = [-1, 0.0, 0.5, 0.2]\n",
    "    datas = [data_a, data_b, data_c]\n",
    "    \n",
    "    size = 5\n",
    "    n_ax = len(datas)\n",
    "    \n",
    "    fig, axs = plt.subplots(\n",
    "        1,\n",
    "        n_ax,\n",
    "        sharey=True,\n",
    "        sharex=False,\n",
    "        figsize=(n_ax * size, size),\n",
    "    )\n",
    "\n",
    "    for ax, data in zip(axs, datas):\n",
    "        ax.boxplot(data, **kwargs)\n",
    "        ax.axes.xaxis.set_visible(False)\n",
    "        ax.axes.yaxis.set_visible(False)\n",
    "        views.utils.fix_borders(ax, visibles=[False, False, False, False])\n",
    "    \n",
    "    y_ticks = styles.simple_ticks([1.0, 0.0])\n",
    "    axs[0].axes.yaxis.set_visible(True)\n",
    "    axs[0].set_yticks(y_ticks)\n",
    "    axs[0].set_ylim((0.0, 1.0))\n",
    "    views.utils.fix_borders(axs[0], visibles=[False, False, False, True])\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=0.5)\n",
    "    #axs[0].set_ylabel(\"Predicted\")\n",
    "    #axs[1].set_xlabel(\"Actual\")\n",
    "    \n",
    "    styles.name_axes(axs)\n",
    "    # styles.simple_axes(axs)\n",
    "    \n",
    "    views.save(\"fig/fig_varience_explained\", fig=fig)\n",
    "    \n",
    "varience_explained_plot()\n",
    "\n",
    "# Different CV splits!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d18be4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d459cf",
   "metadata": {},
   "source": [
    "## Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_views import vapnik as vapnik_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    fig, ax = views.get_plot()\n",
    "\n",
    "mu, sigma = 0, 0.5\n",
    "\n",
    "training_set_size = [2**x for x in range(1, 10)]\n",
    "training_set_size = np.linspace(1, 512, 50)\n",
    "\n",
    "training_set_size = np.array(training_set_size)\n",
    "N = len(training_set_size)\n",
    "\n",
    "error_training = training_set_size\n",
    "error_validation = 1/training_set_size\n",
    "\n",
    "s = np.random.normal(mu, sigma, N)\n",
    "scale = 6.0/np.arange(1, N+1)\n",
    "s *= scale\n",
    "error_training = 5*np.log(error_training) + s\n",
    "\n",
    "s = np.random.normal(mu, sigma, N)\n",
    "scale = 6.0/np.arange(1, N+1)\n",
    "s *= scale\n",
    "error_validation = 5*np.log(error_validation) + 64 + s\n",
    "\n",
    "ax.plot(training_set_size, error_training, \"k--\")\n",
    "ax.plot(training_set_size, error_validation, \"k--\")\n",
    "\n",
    "ax.set_ylabel(\"error\")\n",
    "ax.set_xlabel(\"training set size\")\n",
    "\n",
    "ykeys = [0, 30.0, 60]\n",
    "xkeys = [10, 150, 300, 500]\n",
    "\n",
    "vapnik_views.learning_curve_error(ax, xkeys, ykeys,\n",
    "    x_range=(-20, 500),\n",
    "    y_range=(-5, 60),\n",
    "    loglog=False)\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "font = {\"family\": \"xkcd\", \"fontsize\":15}\n",
    "\n",
    "\n",
    "txt_train = \"Learning for training set\".lower()\n",
    "txt_valid = \"Learning for validation set\".lower()\n",
    "ax.text(150, 50, txt_valid, **font)\n",
    "ax.text(150, 10, txt_train, **font)\n",
    "\n",
    "# ax.arrow(20, 10, 20, 0, head_width=2, head_length=4, head_starts_at_zero=True)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5c7b1",
   "metadata": {},
   "source": [
    "blah blah blah learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "plt.rc('path', effects=[PathEffects.withStroke(linewidth=4, foreground=\"w\")])\n",
    "\n",
    "def get_error(N,a,b):\n",
    "    error = a/N**b\n",
    "    return error\n",
    "\n",
    "def get_error_bad(N, a, b, offset, noise=0.2):\n",
    "    error = a/N**b * (1-np.random.normal(0, noise, 1)) + offset\n",
    "    return error\n",
    "\n",
    "with plt.xkcd():\n",
    "    fig, ax = views.get_plot()\n",
    "\n",
    "mu, sigma = 0, 0.5\n",
    "\n",
    "training_set_size = [10**x for x in range(1, 8)]\n",
    "training_set_size = np.array(training_set_size)\n",
    "N = len(training_set_size)\n",
    "\n",
    "# error_training = 5/training_set_size\n",
    "#\n",
    "# s = np.random.normal(mu, sigma, N)\n",
    "# scale = 6.0/np.arange(1, N+1)\n",
    "# s *= scale\n",
    "# error_training += 64 + s\n",
    "\n",
    "offset = 10\n",
    "\n",
    "error_training = [get_error_bad(x,600,0.3,100) for x in training_set_size]\n",
    "error_training = np.array(error_training)\n",
    "error_a = np.array([get_error_bad(x,10_000,0.7, 5.0) for x in training_set_size])\n",
    "error_b = np.array([get_error_bad(x,10_000,0.7,1.0) for x in training_set_size])\n",
    "\n",
    "ax.plot(training_set_size, error_training)\n",
    "ax.plot(training_set_size, error_a+1.0)\n",
    "ax.plot(training_set_size, error_b)\n",
    "\n",
    "# Models End\n",
    "model_names = [\"A\", \"B\", \"C\"]\n",
    "end_points = []\n",
    "end_points.append(error_training[-1])\n",
    "end_points.append(error_a[-1])\n",
    "end_points.append(error_b[-1])\n",
    "\n",
    "for name, point in zip(model_names, end_points):\n",
    "\n",
    "    font = {\n",
    "        \"family\": \"xkcd\",\n",
    "        \"fontsize\":15,\n",
    "        \"horizontalalignment\": 'right',\n",
    "        \"verticalalignment\": 'center',\n",
    "    }\n",
    "    txtobj = ax.text(10**7, point, name, **font)\n",
    "    txtobj.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "# lines\n",
    "\n",
    "line_data = [10]*N\n",
    "line_data = np.array(line_data) + np.random.normal(0,0.5,N)\n",
    "lineobj = ax.plot(training_set_size, line_data, \"k--\")\n",
    "\n",
    "yticks = [0.1, 1.0, 10, 100, 10**3, 10**4]\n",
    "line_data_y = np.array(yticks)\n",
    "line_data_x = np.array([10**4]*line_data_y.shape[0]) * (1- np.random.normal(0,0.05,line_data_y.shape[0]))\n",
    "lineobj = ax.plot(line_data_x, line_data_y, \"k\", linestyle=\"dotted\")\n",
    "\n",
    "yticks = [0.1, 1.0, 10, 100, 10**3, 10**4]\n",
    "line_data_y = np.array(yticks)\n",
    "line_data_x = np.array([10**5]*line_data_y.shape[0]) * (1- np.random.normal(0,0.05,line_data_y.shape[0]))\n",
    "lineobj = ax.plot(line_data_x, line_data_y, \"k\", linestyle=\"dotted\")\n",
    "\n",
    "\n",
    "lineobj[0].set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "# text\n",
    "\n",
    "font = {\n",
    "    \"family\": \"xkcd\",\n",
    "    \"fontsize\":15,\n",
    "    \"horizontalalignment\": 'center',\n",
    "    \"verticalalignment\": 'center',\n",
    "}\n",
    "\n",
    "txt_valid = \"target error\".lower()\n",
    "txtobj = ax.text(10**2, 10**1, txt_valid, **font)\n",
    "txtobj.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "txt_valid = \"data avail.\".lower()\n",
    "txtobj = ax.text(10**4, 10**3, txt_valid, **font)\n",
    "txtobj.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "txt_valid = \"data need.\".lower()\n",
    "txtobj = ax.text(10**5, 10**3.5, txt_valid, **font)\n",
    "txtobj.set_path_effects([PathEffects.withStroke(linewidth=5, foreground='w')])\n",
    "\n",
    "\n",
    "# labels\n",
    "ax.set_ylabel(\"error\")\n",
    "ax.set_xlabel(\"experience\")\n",
    "\n",
    "# ticks\n",
    "yticks = [10**x for x in range(1, 8)]\n",
    "plt.yticks(yticks)\n",
    "\n",
    "\n",
    "\n",
    "ykeys = [1, 10.0, 100, 1000, 10**4]\n",
    "xkeys = [10**x for x in range(1,8)]\n",
    "# mpl_lc.learning_curve_error(ax, xkeys, ykeys)\n",
    "\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "\n",
    "font = {\"family\": \"xkcd\", \"fontsize\":15}\n",
    "\n",
    "\n",
    "# txt_train = \"Learning for training set\".lower()\n",
    "# txt_valid = \"Learning for validation set\".lower()\n",
    "# ax.text(150, 50, txt_valid, **font)\n",
    "# ax.text(150, 10, txt_train, **font)\n",
    "\n",
    "# ax.arrow(20, 10, 20, 0, head_width=2, head_length=4, head_starts_at_zero=True)\n",
    "\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.minorticks_off()\n",
    "\n",
    "ax.set_xlim((5, max(xkeys)*(1+0.1)))\n",
    "ax.set_ylim((5*10**-1, max(ykeys)))\n",
    "\n",
    "border = [False, False, True, True]\n",
    "spines = ax.spines.items()\n",
    "for direction, spine in spines:\n",
    "    if direction == \"top\":\n",
    "        spine.set_visible(border[0])\n",
    "\n",
    "    if direction == \"right\":\n",
    "        spine.set_visible(border[1])\n",
    "\n",
    "    if direction == \"bottom\":\n",
    "        spine.set_visible(border[2])\n",
    "        spine.set_bounds(min(xkeys), max(xkeys))\n",
    "\n",
    "    if direction == \"left\":\n",
    "        spine.set_visible(border[3])\n",
    "        spine.set_bounds(min(ykeys), max(ykeys))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feeada0",
   "metadata": {},
   "source": [
    "detail learning curve ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffacd82",
   "metadata": {},
   "source": [
    "## Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c96af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
